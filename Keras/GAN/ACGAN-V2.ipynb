{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Input, Dense,Reshape, Conv2D, Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization,Activation,Embedding,multiply\n",
    "from tensorflow.keras.layers import Conv2DTranspose,Flatten, LeakyReLU, concatenate\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(xtr,ytr),_ = mnist.load_data()\n",
    "xtr = xtr.reshape((-1,28,28,1)).astype('float32')/255\n",
    "ytr = to_categorical(ytr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataViewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from GAN.utils import dataViewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viewMnist(mtr):\n",
    "    '''Return from a numpy array an Image'''\n",
    "    mtr = mtr.reshape((28,28))\n",
    "    mtr *= 255\n",
    "    mtr = np.clip(mtr,0,255).astype('uint8')\n",
    "    imshow(mtr,cmap='gray')\n",
    "def saveMnist(mtr,path):\n",
    "    '''Save as file the numpy array'''\n",
    "    mtr = mtr.reshape((28,28))\n",
    "    mtr *= 255\n",
    "    mtr = np.clip(mtr,0,255).astype('uint8')\n",
    "    Image.fromarray(mtr).resize((280,280)).save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vwr = dataViewer(functionView=viewMnist,functionSave=saveMnist,path=\"D:/Project/DeepLearning/GAN/ACGAN/output/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a ACGAN instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(None, 100), (None, 10)] (None, 28, 28, 1)\n",
      "Model: \"generator\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 10)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 110)          0           input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 6272)         696192      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 7, 7, 128)    0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 7, 7, 128)    512         reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 7, 7, 128)    0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 14, 14, 128)  409728      activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 14, 14, 128)  512         conv2d_transpose[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 14, 14, 128)  0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 28, 28, 64)   204864      activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 28, 28, 64)   256         conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 28, 28, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 28, 28, 32)   51232       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 28, 28, 32)   128         conv2d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 28, 28, 32)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 28, 28, 1)    801         activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 28, 28, 1)    0           conv2d_transpose_3[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 1,364,225\n",
      "Trainable params: 1,363,521\n",
      "Non-trainable params: 704\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Generator\n",
    "\n",
    "def build_generator():\n",
    "    # network parameters\n",
    "    kernel_size = 5\n",
    "    layer_filters = [128, 64, 32, 1]\n",
    "    inputs = Input(shape=(100,))\n",
    "    labels = Input(shape=(10,))\n",
    "\n",
    "    inputs = [inputs, labels]\n",
    "    x = concatenate(inputs, axis=1)\n",
    "    x = Dense(7 * 7 * layer_filters[0])(x)\n",
    "    x = Reshape((7, 7, layer_filters[0]))(x)\n",
    "    for filters in layer_filters:\n",
    "        # first two convolution layers use strides = 2\n",
    "        # the last two use strides = 1\n",
    "        if filters > layer_filters[-2]:\n",
    "            strides = 2\n",
    "        else:\n",
    "            strides = 1\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = Conv2DTranspose(filters=filters,kernel_size=kernel_size, strides=strides, padding='same')(x)\n",
    "    x = Activation('sigmoid')(x)\n",
    "    return Model(inputs, x, name='generator')\n",
    "\n",
    "generator = build_generator()\n",
    "print(generator.input_shape,generator.output_shape)\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 28, 28, 1) [(None, 1), (None, 10)]\n",
      "Model: \"discriminator\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, 28, 28, 1)    0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 14, 14, 32)   832         leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 14, 14, 32)   0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 7, 7, 64)     51264       leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 7, 7, 64)     0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 4, 4, 128)    204928      leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 4, 4, 128)    0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 4, 4, 256)    819456      leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 4096)         0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          524416      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            4097        flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           1290        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "RealFake (Activation)           (None, 1)            0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "label (Activation)              (None, 10)           0           dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,606,283\n",
      "Trainable params: 1,606,283\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Discriminator\n",
    "\n",
    "\n",
    "def build_discriminator():\n",
    "    kernel_size = 5\n",
    "    layer_filters = [32, 64, 128, 256]\n",
    "    \n",
    "    inputs = Input(shape=(28,28,1))\n",
    "\n",
    "    x = inputs\n",
    "    for filters in layer_filters:\n",
    "        # first 3 convolution layers use strides = 2\n",
    "        # last one uses strides = 1\n",
    "        if filters == layer_filters[-1]:\n",
    "            strides = 1\n",
    "        else:\n",
    "            strides = 2\n",
    "        x = LeakyReLU(alpha=0.2)(x)\n",
    "        x = Conv2D(filters=filters,kernel_size=kernel_size,strides=strides,padding='same')(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    outputs = Dense(1)(x)\n",
    "    outputs = Activation('sigmoid',name='RealFake')(outputs)\n",
    "    layer = Dense(layer_filters[-2])(x)\n",
    "    labels = Dense(10)(layer)\n",
    "    labels = Activation('softmax', name='label')(labels)\n",
    "    outputs = [outputs, labels]\n",
    "    return Model(inputs, outputs, name='discriminator')\n",
    "\n",
    "\n",
    "discriminator = build_discriminator()\n",
    "print(discriminator.input_shape,discriminator.output_shape)\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from GAN.GAN.LabelGAN import ACGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gan = ACGAN(generator=generator,discriminator=discriminator,DiscrOptimizer=Adam(learning_rate=0.0002, beta_1=0.5),GanOptimizer=Adam(learning_rate=0.0002, beta_1=0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the ACGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.generateBatchEval(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gan.GenerateOutputs(xtest=gan.evaluationInpt,batchSize=16,returnArray=False,dataViewer=vwr,save=True,View=False,epoch=0)\n",
    "gan.GenerateOutputs(batchSize=1,returnArray=False,dataViewer=vwr,save=False,View=True,epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "117/117 [==============================] - 100s 857ms/step\n",
      "Discrimiator: (loss,0.4831579923629761)(RealFake_loss,0.0010683926520869136)(label_loss,0.4820896089076996)(RealFake_accuracy,1.0)(label_accuracy,0.9619140625)\n",
      " \t Adversial: (loss,0.005274565890431404)(RealFake_loss,0.0003419756831135601)(label_loss,0.004932590294629335)(RealFake_accuracy,1.0)(label_accuracy,0.998046875)\n",
      "Epoch 2/30\n",
      "117/117 [==============================] - 105s 898ms/step\n",
      "Discrimiator: (loss,0.126554936170578)(RealFake_loss,0.0016096321633085608)(label_loss,0.12494529783725739)(RealFake_accuracy,1.0)(label_accuracy,0.9814453125)\n",
      " \t Adversial: (loss,0.0004093512543477118)(RealFake_loss,0.0003824133309535682)(label_loss,2.693791248020716e-05)(RealFake_accuracy,1.0)(label_accuracy,1.0)\n",
      "Epoch 3/30\n",
      "117/117 [==============================] - 107s 916ms/step\n",
      "Discrimiator: (loss,0.6781196594238281)(RealFake_loss,0.5507630109786987)(label_loss,0.1273566633462906)(RealFake_accuracy,0.728515625)(label_accuracy,0.9775390625)\n",
      " \t Adversial: (loss,0.4649601876735687)(RealFake_loss,0.46331098675727844)(label_loss,0.0016491999849677086)(RealFake_accuracy,0.888671875)(label_accuracy,1.0)\n",
      "Epoch 4/30\n",
      "117/117 [==============================] - 108s 927ms/step\n",
      "Discrimiator: (loss,0.5748142004013062)(RealFake_loss,0.45499587059020996)(label_loss,0.11981834471225739)(RealFake_accuracy,0.80859375)(label_accuracy,0.9814453125)\n",
      " \t Adversial: (loss,0.13238151371479034)(RealFake_loss,0.11224205046892166)(label_loss,0.02013946883380413)(RealFake_accuracy,1.0)(label_accuracy,0.994140625)\n",
      "Epoch 5/30\n",
      "117/117 [==============================] - 109s 927ms/step\n",
      "Discrimiator: (loss,0.7094711065292358)(RealFake_loss,0.6055285930633545)(label_loss,0.10394252836704254)(RealFake_accuracy,0.65625)(label_accuracy,0.98046875)\n",
      " \t Adversial: (loss,1.0414150953292847)(RealFake_loss,1.0300602912902832)(label_loss,0.01135485339909792)(RealFake_accuracy,0.22265625)(label_accuracy,0.998046875)\n",
      "Epoch 6/30\n",
      "117/117 [==============================] - 112s 954ms/step\n",
      "Discrimiator: (loss,0.7278831601142883)(RealFake_loss,0.6341326236724854)(label_loss,0.09375053644180298)(RealFake_accuracy,0.6103515625)(label_accuracy,0.9775390625)\n",
      " \t Adversial: (loss,0.9149474501609802)(RealFake_loss,0.9059174060821533)(label_loss,0.009030015207827091)(RealFake_accuracy,0.3125)(label_accuracy,0.99609375)\n",
      "Epoch 7/30\n",
      "117/117 [==============================] - 110s 943ms/step\n",
      "Discrimiator: (loss,0.7764101028442383)(RealFake_loss,0.6954904794692993)(label_loss,0.08091960847377777)(RealFake_accuracy,0.5537109375)(label_accuracy,0.9833984375)\n",
      " \t Adversial: (loss,0.8560757637023926)(RealFake_loss,0.8416500091552734)(label_loss,0.014425763860344887)(RealFake_accuracy,0.384765625)(label_accuracy,0.99609375)\n",
      "Epoch 8/30\n",
      "117/117 [==============================] - 111s 947ms/step\n",
      "Discrimiator: (loss,0.8360902070999146)(RealFake_loss,0.7435354590415955)(label_loss,0.09255476295948029)(RealFake_accuracy,0.447265625)(label_accuracy,0.98046875)\n",
      " \t Adversial: (loss,0.7257730960845947)(RealFake_loss,0.6923558115959167)(label_loss,0.03341727331280708)(RealFake_accuracy,0.53515625)(label_accuracy,0.9921875)\n",
      "Epoch 9/30\n",
      "117/117 [==============================] - 112s 953ms/step\n",
      "Discrimiator: (loss,0.7174763083457947)(RealFake_loss,0.6445884108543396)(label_loss,0.07288789749145508)(RealFake_accuracy,0.650390625)(label_accuracy,0.98828125)\n",
      " \t Adversial: (loss,0.7742772102355957)(RealFake_loss,0.7629804015159607)(label_loss,0.011296803131699562)(RealFake_accuracy,0.451171875)(label_accuracy,1.0)\n",
      "Epoch 10/30\n",
      "117/117 [==============================] - 111s 949ms/step\n",
      "Discrimiator: (loss,0.7700730562210083)(RealFake_loss,0.6977060437202454)(label_loss,0.07236701250076294)(RealFake_accuracy,0.5205078125)(label_accuracy,0.9873046875)\n",
      " \t Adversial: (loss,0.802695631980896)(RealFake_loss,0.7966665029525757)(label_loss,0.006029140204191208)(RealFake_accuracy,0.3984375)(label_accuracy,1.0)\n",
      "Epoch 11/30\n",
      "117/117 [==============================] - 111s 949ms/step\n",
      "Discrimiator: (loss,0.7735538482666016)(RealFake_loss,0.7026030421257019)(label_loss,0.07095078378915787)(RealFake_accuracy,0.5283203125)(label_accuracy,0.9853515625)\n",
      " \t Adversial: (loss,0.7804996371269226)(RealFake_loss,0.7755076885223389)(label_loss,0.0049919444136321545)(RealFake_accuracy,0.37890625)(label_accuracy,1.0)\n",
      "Epoch 12/30\n",
      "117/117 [==============================] - 112s 957ms/step\n",
      "Discrimiator: (loss,0.7732778787612915)(RealFake_loss,0.7084956765174866)(label_loss,0.06478223204612732)(RealFake_accuracy,0.5380859375)(label_accuracy,0.9892578125)\n",
      " \t Adversial: (loss,0.7788659930229187)(RealFake_loss,0.7741365432739258)(label_loss,0.004729443695396185)(RealFake_accuracy,0.39453125)(label_accuracy,1.0)\n",
      "Epoch 13/30\n",
      "117/117 [==============================] - 110s 941ms/step\n",
      "Discrimiator: (loss,0.7363582253456116)(RealFake_loss,0.6713225841522217)(label_loss,0.0650356337428093)(RealFake_accuracy,0.6044921875)(label_accuracy,0.9873046875)\n",
      " \t Adversial: (loss,0.7625434398651123)(RealFake_loss,0.7538683414459229)(label_loss,0.008675086311995983)(RealFake_accuracy,0.4609375)(label_accuracy,0.99609375)\n",
      "Epoch 14/30\n",
      "117/117 [==============================] - 109s 932ms/step\n",
      "Discrimiator: (loss,0.7317713499069214)(RealFake_loss,0.6756577491760254)(label_loss,0.05611361935734749)(RealFake_accuracy,0.5908203125)(label_accuracy,0.9912109375)\n",
      " \t Adversial: (loss,0.7267524600028992)(RealFake_loss,0.7224563360214233)(label_loss,0.004296101164072752)(RealFake_accuracy,0.466796875)(label_accuracy,1.0)\n",
      "Epoch 15/30\n",
      "117/117 [==============================] - 110s 942ms/step\n",
      "Discrimiator: (loss,0.7555249929428101)(RealFake_loss,0.7016246318817139)(label_loss,0.053900346159935)(RealFake_accuracy,0.5068359375)(label_accuracy,0.9912109375)\n",
      " \t Adversial: (loss,0.8613690137863159)(RealFake_loss,0.8572198152542114)(label_loss,0.004149182699620724)(RealFake_accuracy,0.23828125)(label_accuracy,1.0)\n",
      "Epoch 16/30\n",
      "117/117 [==============================] - 110s 940ms/step\n",
      "Discrimiator: (loss,0.7476591467857361)(RealFake_loss,0.6911790370941162)(label_loss,0.056480102241039276)(RealFake_accuracy,0.53515625)(label_accuracy,0.98828125)\n",
      " \t Adversial: (loss,0.65975421667099)(RealFake_loss,0.6560395956039429)(label_loss,0.003714607562869787)(RealFake_accuracy,0.6484375)(label_accuracy,1.0)\n",
      "Epoch 17/30\n",
      "117/117 [==============================] - 110s 936ms/step\n",
      "Discrimiator: (loss,0.7448456883430481)(RealFake_loss,0.6926877498626709)(label_loss,0.0521579310297966)(RealFake_accuracy,0.51171875)(label_accuracy,0.9912109375)\n",
      " \t Adversial: (loss,0.6241377592086792)(RealFake_loss,0.6211153268814087)(label_loss,0.003022413235157728)(RealFake_accuracy,0.716796875)(label_accuracy,0.998046875)\n",
      "Epoch 18/30\n",
      "117/117 [==============================] - 110s 940ms/step\n",
      "Discrimiator: (loss,0.7602255344390869)(RealFake_loss,0.7075392603874207)(label_loss,0.052686259150505066)(RealFake_accuracy,0.4951171875)(label_accuracy,0.9912109375)\n",
      " \t Adversial: (loss,0.6267456412315369)(RealFake_loss,0.6236662268638611)(label_loss,0.003079407149925828)(RealFake_accuracy,0.736328125)(label_accuracy,1.0)\n",
      "Epoch 19/30\n",
      "117/117 [==============================] - 109s 933ms/step\n",
      "Discrimiator: (loss,0.7398466467857361)(RealFake_loss,0.691450834274292)(label_loss,0.0483957976102829)(RealFake_accuracy,0.5380859375)(label_accuracy,0.9921875)\n",
      " \t Adversial: (loss,0.7034170031547546)(RealFake_loss,0.6961431503295898)(label_loss,0.007273882161825895)(RealFake_accuracy,0.498046875)(label_accuracy,0.998046875)\n",
      "Epoch 20/30\n",
      "117/117 [==============================] - 109s 930ms/step\n",
      "Discrimiator: (loss,0.7294328212738037)(RealFake_loss,0.6819109320640564)(label_loss,0.047521915286779404)(RealFake_accuracy,0.587890625)(label_accuracy,0.9912109375)\n",
      " \t Adversial: (loss,0.6615710258483887)(RealFake_loss,0.6573054790496826)(label_loss,0.004265530966222286)(RealFake_accuracy,0.6171875)(label_accuracy,1.0)\n",
      "Epoch 21/30\n",
      "117/117 [==============================] - 109s 928ms/step\n",
      "Discrimiator: (loss,0.7283157110214233)(RealFake_loss,0.6846771836280823)(label_loss,0.043638553470373154)(RealFake_accuracy,0.5419921875)(label_accuracy,0.9921875)\n",
      " \t Adversial: (loss,0.6757071614265442)(RealFake_loss,0.6742201447486877)(label_loss,0.001487035653553903)(RealFake_accuracy,0.587890625)(label_accuracy,1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30\n",
      "117/117 [==============================] - 109s 931ms/step\n",
      "Discrimiator: (loss,0.736047625541687)(RealFake_loss,0.694732666015625)(label_loss,0.04131495952606201)(RealFake_accuracy,0.5244140625)(label_accuracy,0.9931640625)\n",
      " \t Adversial: (loss,0.6364108920097351)(RealFake_loss,0.6344609260559082)(label_loss,0.0019499677000567317)(RealFake_accuracy,0.71875)(label_accuracy,1.0)\n",
      "Epoch 23/30\n",
      "117/117 [==============================] - 108s 924ms/step\n",
      "Discrimiator: (loss,0.7322542071342468)(RealFake_loss,0.6972651481628418)(label_loss,0.03498908132314682)(RealFake_accuracy,0.50390625)(label_accuracy,0.994140625)\n",
      " \t Adversial: (loss,0.6407589912414551)(RealFake_loss,0.6353049874305725)(label_loss,0.005454020109027624)(RealFake_accuracy,0.6875)(label_accuracy,1.0)\n",
      "Epoch 24/30\n",
      "117/117 [==============================] - 108s 923ms/step\n",
      "Discrimiator: (loss,0.715584397315979)(RealFake_loss,0.6789386868476868)(label_loss,0.03664570674300194)(RealFake_accuracy,0.5830078125)(label_accuracy,0.994140625)\n",
      " \t Adversial: (loss,0.6653667688369751)(RealFake_loss,0.6634606719017029)(label_loss,0.0019061253406107426)(RealFake_accuracy,0.619140625)(label_accuracy,1.0)\n",
      "Epoch 25/30\n",
      "117/117 [==============================] - 111s 946ms/step\n",
      "Discrimiator: (loss,0.7302504777908325)(RealFake_loss,0.6978146433830261)(label_loss,0.0324358269572258)(RealFake_accuracy,0.533203125)(label_accuracy,0.994140625)\n",
      " \t Adversial: (loss,0.6623222827911377)(RealFake_loss,0.6612955331802368)(label_loss,0.0010267415782436728)(RealFake_accuracy,0.6328125)(label_accuracy,1.0)\n",
      "Epoch 26/30\n",
      "117/117 [==============================] - 109s 933ms/step\n",
      "Discrimiator: (loss,0.7179030776023865)(RealFake_loss,0.6851946711540222)(label_loss,0.03270842880010605)(RealFake_accuracy,0.580078125)(label_accuracy,0.9931640625)\n",
      " \t Adversial: (loss,0.7157321572303772)(RealFake_loss,0.7151075601577759)(label_loss,0.0006246247212402523)(RealFake_accuracy,0.44921875)(label_accuracy,1.0)\n",
      "Epoch 27/30\n",
      "117/117 [==============================] - 107s 913ms/step\n",
      "Discrimiator: (loss,0.7215846180915833)(RealFake_loss,0.6930736899375916)(label_loss,0.028510956093668938)(RealFake_accuracy,0.5244140625)(label_accuracy,0.994140625)\n",
      " \t Adversial: (loss,0.7235267758369446)(RealFake_loss,0.722392201423645)(label_loss,0.0011346022365614772)(RealFake_accuracy,0.458984375)(label_accuracy,1.0)\n",
      "Epoch 28/30\n",
      "117/117 [==============================] - 108s 920ms/step\n",
      "Discrimiator: (loss,0.7261502742767334)(RealFake_loss,0.7010458707809448)(label_loss,0.025104403495788574)(RealFake_accuracy,0.53515625)(label_accuracy,0.994140625)\n",
      " \t Adversial: (loss,0.7118098139762878)(RealFake_loss,0.7095159292221069)(label_loss,0.00229391036555171)(RealFake_accuracy,0.443359375)(label_accuracy,0.998046875)\n",
      "Epoch 29/30\n",
      "117/117 [==============================] - 107s 915ms/step\n",
      "Discrimiator: (loss,0.710289478302002)(RealFake_loss,0.6883814930915833)(label_loss,0.021907979622483253)(RealFake_accuracy,0.5576171875)(label_accuracy,0.994140625)\n",
      " \t Adversial: (loss,0.7106084227561951)(RealFake_loss,0.7029425501823425)(label_loss,0.0076658641919493675)(RealFake_accuracy,0.482421875)(label_accuracy,0.998046875)\n",
      "Epoch 30/30\n",
      "117/117 [==============================] - 107s 914ms/step\n",
      "Discrimiator: (loss,0.713330090045929)(RealFake_loss,0.6896440982818604)(label_loss,0.023685963824391365)(RealFake_accuracy,0.5361328125)(label_accuracy,0.9931640625)\n",
      " \t Adversial: (loss,0.6450504064559937)(RealFake_loss,0.6417081952095032)(label_loss,0.003342227078974247)(RealFake_accuracy,0.693359375)(label_accuracy,0.998046875)\n"
     ]
    }
   ],
   "source": [
    "gan.train(x_train=[xtr,ytr],batch_size=1024,epoch=30,evalStep=(1,10),dataViewer=vwr,pathSave='D:/Project/DeepLearning/GAN/ACGAN/save')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
