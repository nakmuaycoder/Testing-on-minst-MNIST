{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InfoGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Input, Dense,Reshape, Conv2D, Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization,Activation,Embedding,multiply\n",
    "from tensorflow.keras.layers import Conv2DTranspose,Flatten, LeakyReLU, concatenate\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(xtr,ytr),_ = mnist.load_data()\n",
    "xtr = xtr.reshape((-1,28,28,1)).astype('float32')/255\n",
    "ytr = to_categorical(ytr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataViewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GAN.utils import dataViewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from GAN.utils import dataViewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viewMnist(mtr):\n",
    "    '''Return from a numpy array an Image'''\n",
    "    mtr = mtr.reshape((28,28))\n",
    "    mtr *= 255\n",
    "    mtr = np.clip(mtr,0,255).astype('uint8')\n",
    "    imshow(mtr,cmap='gray')\n",
    "def saveMnist(mtr,path):\n",
    "    '''Save as file the numpy array'''\n",
    "    mtr = mtr.reshape((28,28))\n",
    "    mtr *= 255\n",
    "    mtr = np.clip(mtr,0,255).astype('uint8')\n",
    "    Image.fromarray(mtr).resize((280,280)).save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vwr = dataViewer(functionView=viewMnist,functionSave=saveMnist,path=\"D:/Project/DeepLearning/GAN/InfoGAN/output/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create  a InfoGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, 28, 28, 1)    0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 14, 14, 32)   832         leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 14, 14, 32)   0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 7, 7, 64)     51264       leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 7, 7, 64)     0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 4, 4, 128)    204928      leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 4, 4, 128)    0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 4, 4, 256)    819456      leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 4096)         0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          524416      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            4097        flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           1290        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            129         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            129         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "label (Activation)              (None, 10)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "code1 (Activation)              (None, 1)            0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "code2 (Activation)              (None, 1)            0           dense_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,606,541\n",
      "Trainable params: 1,606,541\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def discriminator():\n",
    "    kernel_size = 5\n",
    "    layer_filters = [32, 64, 128, 256]\n",
    "    num_labels = 10\n",
    "    num_codes=2\n",
    "    \n",
    "    inputs = Input(shape=(28,28,1))#mnist input\n",
    "    \n",
    "    \n",
    "    x = inputs\n",
    "    for filters in layer_filters:\n",
    "        # first 3 convolution layers use strides = 2\n",
    "        # last one uses strides = 1\n",
    "        if filters == layer_filters[-1]:\n",
    "            strides = 1\n",
    "        else:\n",
    "            strides = 2\n",
    "        x = LeakyReLU(alpha=0.2)(x)\n",
    "        x = Conv2D(filters=filters,kernel_size=kernel_size,strides=strides,padding='same')(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    # default output is probability that the image is real\n",
    "    outputs = Dense(1)(x)\n",
    "    outputs = Activation('sigmoid')(outputs)\n",
    "    layer = Dense(layer_filters[-2])(x)\n",
    "    labels = Dense(num_labels)(layer)\n",
    "    labels = Activation('softmax', name='label')(labels)\n",
    "    code1 = Dense(1)(layer)\n",
    "    code1 = Activation('sigmoid', name='code1')(code1)\n",
    "    # 4th output is 1-dim continuous Q of 2nd c given x\n",
    "    code2 = Dense(1)(layer)\n",
    "    code2 = Activation('sigmoid', name='code2')(code2)\n",
    "    outputs = [outputs, labels, code1, code2]\n",
    "    return Model(inputs, outputs, name='discriminator')\n",
    "\n",
    "discriminator = discriminator()\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 10)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 112)          0           input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 6272)         708736      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 7, 7, 128)    0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 7, 7, 128)    512         reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 7, 7, 128)    0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 14, 14, 128)  409728      activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 14, 14, 128)  512         conv2d_transpose[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 14, 14, 128)  0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 28, 28, 64)   204864      activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 28, 28, 64)   256         conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 28, 28, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 28, 28, 32)   51232       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 28, 28, 32)   128         conv2d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 28, 28, 32)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 28, 28, 1)    801         activation_4[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 1,376,769\n",
      "Trainable params: 1,376,065\n",
      "Non-trainable params: 704\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def generator():\n",
    "    kernel_size = 5\n",
    "    layer_filters = [128, 64, 32, 1]    \n",
    "    inputs = Input(shape=(100,))\n",
    "    labels = Input(shape=(10,))\n",
    "    codes = [ Input(shape=(1,)),Input(shape=(1,))  ]\n",
    "\n",
    "    inputs = [inputs, labels] + codes\n",
    "    x = concatenate(inputs, axis=1)\n",
    "    x = Dense(7 * 7 * layer_filters[0])(x)\n",
    "    x = Reshape((7, 7, layer_filters[0]))(x)\n",
    "\n",
    "    for filters in layer_filters:\n",
    "        # first two convolution layers use strides = 2\n",
    "        # the last two use strides = 1\n",
    "        if filters > layer_filters[-2]:\n",
    "            strides = 2\n",
    "        else:\n",
    "            strides = 1\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = Conv2DTranspose(filters=filters, kernel_size=kernel_size,strides=strides, padding='same')(x)\n",
    "\n",
    "    return Model(inputs, x, name='generator')\n",
    "\n",
    "generator = generator()\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GAN.GAN.AttributeGAN import INFOGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = INFOGAN(generator=generator,discriminator=discriminator,DiscrOptimizer=Adam(learning_rate=0.0002, beta_1=0.5),GanOptimizer=Adam(learning_rate=0.0002, beta_1=0.5),loss_weights=[1.0, 1.0, 0.5, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate a batch of evaluation with all the label\n",
    "gan.generateBatchEval(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gan.GenerateOutputs(xtest=gan.evaluationInpt,batchSize=16,returnArray=False,dataViewer=vwr,save=True,View=False,epoch=0)\n",
    "gan.GenerateOutputs(batchSize=1,returnArray=False,dataViewer=vwr,save=False,View=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "117/117 [==============================] - 134s 1s/step\n",
      "Discrimiator: (loss,-0.869175136089325)(activation_loss,0.0010509981075301766)(label_loss,0.32877546548843384)(code1_loss,-1.313093662261963)(code2_loss,-1.0849095582962036)(activation_accuracy,1.0)(label_accuracy,0.94140625)(code1_accuracy,0.0)(code2_accuracy,0.0)\n",
      " \t Adversial: (loss,-2.816946506500244)(activation_loss,0.0006583263748325408)(label_loss,0.01849997416138649)(code1_loss,-3.060568332672119)(code2_loss,-2.6116414070129395)(activation_accuracy,1.0)(label_accuracy,0.994140625)(code1_accuracy,0.0)(code2_accuracy,0.0)\n",
      "Epoch 2/30\n",
      "117/117 [==============================] - 139s 1s/step\n",
      "Discrimiator: (loss,-1.3448143005371094)(activation_loss,0.013444172218441963)(label_loss,0.17660018801689148)(code1_loss,-1.6002631187438965)(code2_loss,-1.469454050064087)(activation_accuracy,1.0)(label_accuracy,0.9482421875)(code1_accuracy,0.0)(code2_accuracy,0.0)\n",
      " \t Adversial: (loss,-3.2387337684631348)(activation_loss,8.447597792837769e-05)(label_loss,0.0014617565320804715)(code1_loss,-3.15193772315979)(code2_loss,-3.328622579574585)(activation_accuracy,1.0)(label_accuracy,1.0)(code1_accuracy,0.0)(code2_accuracy,0.0)\n",
      "Epoch 3/30\n",
      "117/117 [==============================] - 140s 1s/step\n",
      "Discrimiator: (loss,-1.4383260011672974)(activation_loss,0.029379598796367645)(label_loss,0.13266822695732117)(code1_loss,-1.590965986251831)(code2_loss,-1.6097817420959473)(activation_accuracy,0.9990234375)(label_accuracy,0.9658203125)(code1_accuracy,0.0)(code2_accuracy,0.0)\n",
      " \t Adversial: (loss,-3.210444927215576)(activation_loss,0.007121844682842493)(label_loss,0.0010433470597490668)(code1_loss,-3.40452241897583)(code2_loss,-3.032698154449463)(activation_accuracy,1.0)(label_accuracy,1.0)(code1_accuracy,0.0)(code2_accuracy,0.0)\n",
      "Epoch 4/30\n",
      "117/117 [==============================] - 141s 1s/step\n",
      "Discrimiator: (loss,-1.1017487049102783)(activation_loss,0.19321173429489136)(label_loss,0.10914720594882965)(code1_loss,-1.1541812419891357)(code2_loss,-1.6540340185165405)(activation_accuracy,0.966796875)(label_accuracy,0.9619140625)(code1_accuracy,0.0)(code2_accuracy,0.0)\n",
      " \t Adversial: (loss,-3.0413081645965576)(activation_loss,0.10590966790914536)(label_loss,0.015074304305016994)(code1_loss,-3.0951039791107178)(code2_loss,-3.229480266571045)(activation_accuracy,0.998046875)(label_accuracy,0.998046875)(code1_accuracy,0.0)(code2_accuracy,0.0)\n",
      "Epoch 5/30\n",
      "117/117 [==============================] - 141s 1s/step\n",
      "Discrimiator: (loss,-1.2970106601715088)(activation_loss,0.03127045929431915)(label_loss,0.10325941443443298)(code1_loss,-1.490942358970642)(code2_loss,-1.3721387386322021)(activation_accuracy,0.9921875)(label_accuracy,0.974609375)(code1_accuracy,0.0)(code2_accuracy,0.0)\n",
      " \t Adversial: (loss,-2.91329288482666)(activation_loss,0.03895919770002365)(label_loss,0.002628341317176819)(code1_loss,-2.905736207962036)(code2_loss,-3.0040247440338135)(activation_accuracy,1.0)(label_accuracy,0.998046875)(code1_accuracy,0.0)(code2_accuracy,0.0)\n",
      "Epoch 6/30\n",
      "117/117 [==============================] - 142s 1s/step\n",
      "Discrimiator: (loss,-1.026360273361206)(activation_loss,0.24333980679512024)(label_loss,0.08534880727529526)(code1_loss,-1.3243463039398193)(code2_loss,-1.3857516050338745)(activation_accuracy,0.9228515625)(label_accuracy,0.9697265625)(code1_accuracy,0.0)(code2_accuracy,0.0)\n",
      " \t Adversial: (loss,-0.6704459190368652)(activation_loss,2.3456528186798096)(label_loss,0.011724617332220078)(code1_loss,-3.2097997665405273)(code2_loss,-2.8458471298217773)(activation_accuracy,0.0)(label_accuracy,0.998046875)(code1_accuracy,0.0)(code2_accuracy,0.0)\n",
      "Epoch 7/30\n",
      "117/117 [==============================] - 143s 1s/step\n",
      "Discrimiator: (loss,-1.2066802978515625)(activation_loss,0.1718364953994751)(label_loss,0.105669304728508)(code1_loss,-1.5013246536254883)(code2_loss,-1.4670474529266357)(activation_accuracy,0.97265625)(label_accuracy,0.9716796875)(code1_accuracy,0.0)(code2_accuracy,0.0)\n",
      " \t Adversial: (loss,-2.163374423980713)(activation_loss,0.9442929029464722)(label_loss,0.027425343170762062)(code1_loss,-3.197035074234009)(code2_loss,-3.073150396347046)(activation_accuracy,0.294921875)(label_accuracy,0.99609375)(code1_accuracy,0.0)(code2_accuracy,0.0)\n",
      "Epoch 8/30\n",
      "117/117 [==============================] - 147s 1s/step\n",
      "Discrimiator: (loss,-1.0150413513183594)(activation_loss,0.3778356909751892)(label_loss,0.13883772492408752)(code1_loss,-1.4606472253799438)(code2_loss,-1.6027824878692627)(activation_accuracy,0.8681640625)(label_accuracy,0.958984375)(code1_accuracy,0.0)(code2_accuracy,0.0)\n",
      " \t Adversial: (loss,-0.27676355838775635)(activation_loss,2.7147414684295654)(label_loss,0.027496028691530228)(code1_loss,-3.1021361351013184)(code2_loss,-2.935866117477417)(activation_accuracy,0.025390625)(label_accuracy,0.994140625)(code1_accuracy,0.0)(code2_accuracy,0.0)\n",
      "Epoch 9/30\n",
      "117/117 [==============================] - 143s 1s/step\n",
      "Discrimiator: (loss,-1.0537071228027344)(activation_loss,0.3712647259235382)(label_loss,0.11160558462142944)(code1_loss,-1.5687599182128906)(code2_loss,-1.5043950080871582)(activation_accuracy,0.8720703125)(label_accuracy,0.966796875)(code1_accuracy,0.0)(code2_accuracy,0.0)\n",
      " \t Adversial: (loss,-2.123782157897949)(activation_loss,1.1484930515289307)(label_loss,0.012666766531765461)(code1_loss,-3.2281970977783203)(code2_loss,-3.341686725616455)(activation_accuracy,0.26171875)(label_accuracy,0.998046875)(code1_accuracy,0.0)(code2_accuracy,0.0)\n",
      "Epoch 10/30\n",
      "117/117 [==============================] - 142s 1s/step\n",
      "Discrimiator: (loss,-0.8767048120498657)(activation_loss,0.538692831993103)(label_loss,0.08152075111865997)(code1_loss,-1.5972563028335571)(code2_loss,-1.396580457687378)(activation_accuracy,0.71875)(label_accuracy,0.9765625)(code1_accuracy,0.0)(code2_accuracy,0.0)\n",
      " \t Adversial: (loss,-2.1774160861968994)(activation_loss,0.7371411323547363)(label_loss,0.03591315075755119)(code1_loss,-3.1562509536743164)(code2_loss,-2.74468994140625)(activation_accuracy,0.4921875)(label_accuracy,0.99609375)(code1_accuracy,0.0)(code2_accuracy,0.0)\n",
      "Epoch 11/30\n",
      "117/117 [==============================] - 381s 3s/step\n",
      "Discrimiator: (loss,-0.9555173516273499)(activation_loss,0.5232999324798584)(label_loss,0.08556480705738068)(code1_loss,-1.6418826580047607)(code2_loss,-1.4868814945220947)(activation_accuracy,0.71875)(label_accuracy,0.974609375)(code1_accuracy,0.0)(code2_accuracy,0.0)\n",
      " \t Adversial: (loss,-2.490821599960327)(activation_loss,0.6174933314323425)(label_loss,0.037222400307655334)(code1_loss,-3.171252965927124)(code2_loss,-3.119821786880493)(activation_accuracy,0.6328125)(label_accuracy,0.984375)(code1_accuracy,0.0)(code2_accuracy,0.0)\n",
      "Epoch 12/30\n",
      "117/117 [==============================] - 142s 1s/step\n",
      "Discrimiator: (loss,-0.9956176280975342)(activation_loss,0.5335237979888916)(label_loss,0.09320010989904404)(code1_loss,-1.3889920711517334)(code2_loss,-1.8556909561157227)(activation_accuracy,0.7607421875)(label_accuracy,0.97265625)(code1_accuracy,0.0)(code2_accuracy,0.0)\n",
      " \t Adversial: (loss,-2.0777249336242676)(activation_loss,1.1085997819900513)(label_loss,0.028189051896333694)(code1_loss,-3.2808001041412354)(code2_loss,-3.1482276916503906)(activation_accuracy,0.185546875)(label_accuracy,0.9921875)(code1_accuracy,0.0)(code2_accuracy,0.0)\n",
      "Epoch 13/30\n",
      "117/117 [==============================] - 141s 1s/step\n",
      "Discrimiator: (loss,-1.0032587051391602)(activation_loss,0.4955110251903534)(label_loss,0.07112007588148117)(code1_loss,-1.5168275833129883)(code2_loss,-1.6229521036148071)(activation_accuracy,0.79296875)(label_accuracy,0.974609375)(code1_accuracy,0.0)(code2_accuracy,0.0)\n",
      " \t Adversial: (loss,-2.3924148082733154)(activation_loss,0.8692376017570496)(label_loss,0.02013564109802246)(code1_loss,-3.4008679389953613)(code2_loss,-3.162708044052124)(activation_accuracy,0.34765625)(label_accuracy,1.0)(code1_accuracy,0.0)(code2_accuracy,0.0)\n",
      "Epoch 14/30\n",
      "117/117 [==============================] - 142s 1s/step\n",
      "Discrimiator: (loss,-0.8351673483848572)(activation_loss,0.542927622795105)(label_loss,0.09833475202322006)(code1_loss,-1.5249073505401611)(code2_loss,-1.4279520511627197)(activation_accuracy,0.716796875)(label_accuracy,0.966796875)(code1_accuracy,0.0)(code2_accuracy,0.0)\n",
      " \t Adversial: (loss,-1.9302104711532593)(activation_loss,1.139034390449524)(label_loss,0.0203283429145813)(code1_loss,-3.2529609203338623)(code2_loss,-2.9261856079101562)(activation_accuracy,0.111328125)(label_accuracy,0.998046875)(code1_accuracy,0.0)(code2_accuracy,0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30\n",
      "117/117 [==============================] - 141s 1s/step\n",
      "Discrimiator: (loss,-0.9257610440254211)(activation_loss,0.6230970621109009)(label_loss,0.06643275916576385)(code1_loss,-1.5768966674804688)(code2_loss,-1.6536850929260254)(activation_accuracy,0.59765625)(label_accuracy,0.98046875)(code1_accuracy,0.0)(code2_accuracy,0.0)\n",
      " \t Adversial: (loss,-1.5590510368347168)(activation_loss,1.748488187789917)(label_loss,0.011205571703612804)(code1_loss,-3.3562052249908447)(code2_loss,-3.2812843322753906)(activation_accuracy,0.009765625)(label_accuracy,1.0)(code1_accuracy,0.0)(code2_accuracy,0.0)\n",
      "Epoch 16/30\n",
      "117/117 [==============================] - 141s 1s/step\n",
      "Discrimiator: (loss,-0.7598952054977417)(activation_loss,0.5436848998069763)(label_loss,0.06587083637714386)(code1_loss,-1.5117077827453613)(code2_loss,-1.22719407081604)(activation_accuracy,0.7236328125)(label_accuracy,0.9794921875)(code1_accuracy,0.0)(code2_accuracy,0.0)\n",
      " \t Adversial: (loss,-2.1696765422821045)(activation_loss,0.770176112651825)(label_loss,0.019890449941158295)(code1_loss,-2.763561487197876)(code2_loss,-3.1559245586395264)(activation_accuracy,0.45703125)(label_accuracy,0.998046875)(code1_accuracy,0.0)(code2_accuracy,0.0)\n",
      "Epoch 17/30\n",
      "117/117 [==============================] - 142s 1s/step\n",
      "Discrimiator: (loss,-1.2197680473327637)(activation_loss,0.5539575815200806)(label_loss,0.0473509207367897)(code1_loss,-1.7194113731384277)(code2_loss,-1.9227418899536133)(activation_accuracy,0.724609375)(label_accuracy,0.984375)(code1_accuracy,0.0)(code2_accuracy,0.0)\n",
      " \t Adversial: (loss,-1.7519707679748535)(activation_loss,1.5017985105514526)(label_loss,0.011671752668917179)(code1_loss,-3.087080478668213)(code2_loss,-3.4438016414642334)(activation_accuracy,0.01953125)(label_accuracy,1.0)(code1_accuracy,0.0)(code2_accuracy,0.0)\n",
      "Epoch 18/30\n",
      "117/117 [==============================] - 142s 1s/step\n",
      "Discrimiator: (loss,-0.7236636877059937)(activation_loss,0.5523958802223206)(label_loss,0.044709980487823486)(code1_loss,-1.2487952709197998)(code2_loss,-1.3927438259124756)(activation_accuracy,0.740234375)(label_accuracy,0.984375)(code1_accuracy,0.0)(code2_accuracy,0.0)\n",
      " \t Adversial: (loss,-2.199049949645996)(activation_loss,0.6296868324279785)(label_loss,0.022109758108854294)(code1_loss,-2.773064613342285)(code2_loss,-2.9286282062530518)(activation_accuracy,0.66015625)(label_accuracy,0.9921875)(code1_accuracy,0.0)(code2_accuracy,0.0)\n",
      "Epoch 19/30\n",
      "117/117 [==============================] - 143s 1s/step\n",
      "Discrimiator: (loss,-0.9996349215507507)(activation_loss,0.5698287487030029)(label_loss,0.041388288140296936)(code1_loss,-1.3553982973098755)(code2_loss,-1.8663055896759033)(activation_accuracy,0.6611328125)(label_accuracy,0.9873046875)(code1_accuracy,0.0)(code2_accuracy,0.0)\n",
      " \t Adversial: (loss,-2.834109306335449)(activation_loss,0.4691230058670044)(label_loss,0.013693108223378658)(code1_loss,-3.2963149547576904)(code2_loss,-3.337536096572876)(activation_accuracy,0.83984375)(label_accuracy,0.99609375)(code1_accuracy,0.0)(code2_accuracy,0.0)\n",
      "Epoch 20/30\n",
      "117/117 [==============================] - 140s 1s/step\n",
      "Discrimiator: (loss,-0.8798641562461853)(activation_loss,0.5848625898361206)(label_loss,0.04203197360038757)(code1_loss,-1.6195286512374878)(code2_loss,-1.393988847732544)(activation_accuracy,0.6669921875)(label_accuracy,0.9873046875)(code1_accuracy,0.0)(code2_accuracy,0.0)\n",
      " \t Adversial: (loss,-1.180898904800415)(activation_loss,1.9728405475616455)(label_loss,0.00579461082816124)(code1_loss,-3.1828348636627197)(code2_loss,-3.136233329772949)(activation_accuracy,0.005859375)(label_accuracy,1.0)(code1_accuracy,0.0)(code2_accuracy,0.0)\n",
      "Epoch 21/30\n",
      "117/117 [==============================] - 141s 1s/step\n",
      "Discrimiator: (loss,-0.8624770641326904)(activation_loss,0.6235881447792053)(label_loss,0.04550670459866524)(code1_loss,-1.5530776977539062)(code2_loss,-1.5100661516189575)(activation_accuracy,0.591796875)(label_accuracy,0.9833984375)(code1_accuracy,0.0)(code2_accuracy,0.0)\n",
      " \t Adversial: (loss,-1.7918906211853027)(activation_loss,1.593337059020996)(label_loss,0.009634814225137234)(code1_loss,-3.4543817043304443)(code2_loss,-3.335343360900879)(activation_accuracy,0.029296875)(label_accuracy,0.998046875)(code1_accuracy,0.0)(code2_accuracy,0.0)\n",
      "Epoch 22/30\n",
      "117/117 [==============================] - 141s 1s/step\n",
      "Discrimiator: (loss,-1.0005543231964111)(activation_loss,0.5553067922592163)(label_loss,0.04305205121636391)(code1_loss,-1.6326459646224976)(code2_loss,-1.5651805400848389)(activation_accuracy,0.6884765625)(label_accuracy,0.98828125)(code1_accuracy,0.0)(code2_accuracy,0.0)\n",
      " \t Adversial: (loss,-2.4657719135284424)(activation_loss,0.4985208809375763)(label_loss,0.022607561200857162)(code1_loss,-3.060488224029541)(code2_loss,-2.9133124351501465)(activation_accuracy,0.8359375)(label_accuracy,0.994140625)(code1_accuracy,0.0)(code2_accuracy,0.0)\n",
      "Epoch 23/30\n",
      "117/117 [==============================] - 140s 1s/step\n",
      "Discrimiator: (loss,-0.8582819104194641)(activation_loss,0.677198052406311)(label_loss,0.037992753088474274)(code1_loss,-1.6683142185211182)(code2_loss,-1.4786312580108643)(activation_accuracy,0.6298828125)(label_accuracy,0.9892578125)(code1_accuracy,0.0)(code2_accuracy,0.0)\n",
      " \t Adversial: (loss,-2.139284610748291)(activation_loss,0.8048891425132751)(label_loss,0.0788792073726654)(code1_loss,-3.1358089447021484)(code2_loss,-2.91029691696167)(activation_accuracy,0.5625)(label_accuracy,0.978515625)(code1_accuracy,0.0)(code2_accuracy,0.0)\n",
      "Epoch 24/30\n",
      "117/117 [==============================] - 139s 1s/step\n",
      "Discrimiator: (loss,-0.9027103185653687)(activation_loss,0.5771744251251221)(label_loss,0.03943106159567833)(code1_loss,-1.287535548210144)(code2_loss,-1.7510960102081299)(activation_accuracy,0.6689453125)(label_accuracy,0.9892578125)(code1_accuracy,0.0)(code2_accuracy,0.0)\n",
      " \t Adversial: (loss,-2.2819371223449707)(activation_loss,0.6661328673362732)(label_loss,0.006205157842487097)(code1_loss,-2.9385886192321777)(code2_loss,-2.969961643218994)(activation_accuracy,0.591796875)(label_accuracy,1.0)(code1_accuracy,0.0)(code2_accuracy,0.0)\n",
      "Epoch 25/30\n",
      "117/117 [==============================] - 139s 1s/step\n",
      "Discrimiator: (loss,-0.5693404674530029)(activation_loss,0.8936833739280701)(label_loss,0.031254347413778305)(code1_loss,-1.3800227642059326)(code2_loss,-1.6085336208343506)(activation_accuracy,0.544921875)(label_accuracy,0.9931640625)(code1_accuracy,0.0)(code2_accuracy,0.0)\n",
      " \t Adversial: (loss,-2.312351703643799)(activation_loss,0.7424643039703369)(label_loss,0.027866454795002937)(code1_loss,-3.080352306365967)(code2_loss,-3.085012674331665)(activation_accuracy,0.576171875)(label_accuracy,0.99609375)(code1_accuracy,0.0)(code2_accuracy,0.0)\n",
      "Epoch 26/30\n",
      "117/117 [==============================] - 141s 1s/step\n",
      "Discrimiator: (loss,-1.124061942100525)(activation_loss,0.5375749468803406)(label_loss,0.03110227733850479)(code1_loss,-1.7728229761123657)(code2_loss,-1.6126554012298584)(activation_accuracy,0.703125)(label_accuracy,0.9921875)(code1_accuracy,0.0)(code2_accuracy,0.0)\n",
      " \t Adversial: (loss,-2.19754695892334)(activation_loss,1.0118000507354736)(label_loss,0.010521761141717434)(code1_loss,-3.208878517150879)(code2_loss,-3.2308592796325684)(activation_accuracy,0.298828125)(label_accuracy,0.99609375)(code1_accuracy,0.0)(code2_accuracy,0.0)\n",
      "Epoch 27/30\n",
      "117/117 [==============================] - 139s 1s/step\n",
      "Discrimiator: (loss,-1.1594592332839966)(activation_loss,0.3449404239654541)(label_loss,0.024672258645296097)(code1_loss,-1.4620673656463623)(code2_loss,-1.596076488494873)(activation_accuracy,0.9326171875)(label_accuracy,0.9931640625)(code1_accuracy,0.0)(code2_accuracy,0.0)\n",
      " \t Adversial: (loss,-2.385711431503296)(activation_loss,1.0525600910186768)(label_loss,0.007477776613086462)(code1_loss,-3.356051206588745)(code2_loss,-3.535447359085083)(activation_accuracy,0.33203125)(label_accuracy,0.998046875)(code1_accuracy,0.0)(code2_accuracy,0.0)\n",
      "Epoch 28/30\n",
      "117/117 [==============================] - 139s 1s/step\n",
      "Discrimiator: (loss,-1.1826921701431274)(activation_loss,0.4231937527656555)(label_loss,0.042994655668735504)(code1_loss,-1.6346529722213745)(code2_loss,-1.663108229637146)(activation_accuracy,0.8564453125)(label_accuracy,0.9873046875)(code1_accuracy,0.0)(code2_accuracy,0.0)\n",
      " \t Adversial: (loss,-1.8351891040802002)(activation_loss,1.1768213510513306)(label_loss,0.004755576606839895)(code1_loss,-2.9091811180114746)(code2_loss,-3.1243510246276855)(activation_accuracy,0.265625)(label_accuracy,1.0)(code1_accuracy,0.0)(code2_accuracy,0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30\n",
      "117/117 [==============================] - 139s 1s/step\n",
      "Discrimiator: (loss,-0.8300780653953552)(activation_loss,0.536984920501709)(label_loss,0.03922406584024429)(code1_loss,-1.4457083940505981)(code2_loss,-1.3668657541275024)(activation_accuracy,0.70703125)(label_accuracy,0.9892578125)(code1_accuracy,0.0)(code2_accuracy,0.0)\n",
      " \t Adversial: (loss,-2.3322787284851074)(activation_loss,1.1936508417129517)(label_loss,0.0092550003901124)(code1_loss,-3.4438388347625732)(code2_loss,-3.626530170440674)(activation_accuracy,0.23828125)(label_accuracy,0.998046875)(code1_accuracy,0.0)(code2_accuracy,0.0)\n",
      "Epoch 30/30\n",
      "117/117 [==============================] - 139s 1s/step\n",
      "Discrimiator: (loss,-1.2275117635726929)(activation_loss,0.5810887813568115)(label_loss,0.019903084263205528)(code1_loss,-1.7679545879364014)(code2_loss,-1.8890526294708252)(activation_accuracy,0.7216796875)(label_accuracy,0.9951171875)(code1_accuracy,0.0)(code2_accuracy,0.0)\n",
      " \t Adversial: (loss,-1.9245291948318481)(activation_loss,1.1878608465194702)(label_loss,0.006552851293236017)(code1_loss,-3.3124184608459473)(code2_loss,-2.9254672527313232)(activation_accuracy,0.0859375)(label_accuracy,0.998046875)(code1_accuracy,0.0)(code2_accuracy,0.0)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gan.train(x_train=[xtr,ytr],batch_size=1024,epoch=30,evalStep=(1,10),dataViewer=vwr,pathSave='D:/Project/DeepLearning/GAN/InfoGAN/save')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the impact of X.\n",
    "The vector $\\forall i \\in \\mathbb{N}^{\\star}  X_i \\sim \\mathcal{N}(0,1)$ so 99% of the value are in the range $[-3;3]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compareX(digit):\n",
    "    x = np.asarray([i*(6/10) -3  for i in range(11)])\n",
    "    evl = gan.rdmGenInput(batchSize=1)\n",
    "    evl[1] = np.zeros([1, 10])\n",
    "    evl[1][0,digit] = 1\n",
    "    for i in x:\n",
    "        #row    \n",
    "        for j in x:\n",
    "            #Column\n",
    "            evl[2] = np.array([[i]]).reshape((1,1))\n",
    "            evl[3] = np.array([[j]]).reshape((1,1))\n",
    "            #Get the generate mnist\n",
    "            mtr = gan.generator.predict(evl)\n",
    "            mtr = mtr.reshape((28,28))\n",
    "            #construct the line\n",
    "            if j == x[0]:\n",
    "                line = mtr\n",
    "            else:\n",
    "                line = np.concatenate([line,mtr] ,axis= 1)\n",
    "        if i == x[0]:\n",
    "            #if first row\n",
    "            res = line\n",
    "        else:\n",
    "            res = np.concatenate([res,line],axis= 0  )\n",
    "\n",
    "    plt.imshow(res, cmap='gray')\n",
    "    plt.title('Impact of X vector on the nubmer {}'.format(digit))\n",
    "    plt.savefig('D:/Project/DeepLearning/GAN/InfoGAN/output/digit_{}.jpg'.format(digit))\n",
    "\n",
    "for i in range(10):\n",
    "    compareX(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
