{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WGAN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow\n",
    "from tensorflow.keras.layers import Conv2DTranspose,BatchNormalization\n",
    "from tensorflow.keras.layers import Input,LeakyReLU,Conv2D,Flatten,Dense,Activation,Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(xtr,_),_ = mnist.load_data()\n",
    "xtr = xtr.reshape((-1,28,28,1)).astype('float32')/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataViewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from GAN.utils import dataViewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viewMnist(mtr):\n",
    "    '''Return from a numpy array an Image'''\n",
    "    mtr = mtr.reshape((28,28))\n",
    "    mtr *= 255\n",
    "    mtr = np.clip(mtr,0,255).astype('uint8')\n",
    "    imshow(mtr,cmap='gray')\n",
    "def saveMnist(mtr,path):\n",
    "    '''Save as file the numpy array'''\n",
    "    mtr = mtr.reshape((28,28))\n",
    "    mtr *= 255\n",
    "    mtr = np.clip(mtr,0,255).astype('uint8')\n",
    "    Image.fromarray(mtr).resize((280,280)).save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vwr = dataViewer(functionView=viewMnist,functionSave=saveMnist,path=\"D:/Project/DeepLearning/GAN/WGAN/output/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a WGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GAN.GAN.SimpleGAN import WGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "discriminator_input (InputLa [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 14, 14, 32)        832       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 7, 7, 64)          51264     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 4, 4, 128)         204928    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 256)         819456    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 1,080,577\n",
      "Trainable params: 1,080,577\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def buildDisc():\n",
    "    '''Buid the discriminator'''\n",
    "    input_shape = (28, 28, 1)\n",
    "    inputs = Input(shape=input_shape, name='discriminator_input')\n",
    "    kernel_size = 5\n",
    "    layer_filters = [32, 64, 128, 256]\n",
    "    x = inputs\n",
    "    for filters in layer_filters:\n",
    "        # first 3 convolution layers use strides = 2\n",
    "        # last one uses strides = 1\n",
    "        if filters == layer_filters[-1]:\n",
    "            strides = 1\n",
    "        else:\n",
    "            strides = 2\n",
    "        x = LeakyReLU(alpha=0.2)(x)\n",
    "        x = Conv2D(filters=filters,kernel_size=kernel_size,strides=strides,padding='same')(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1,activation='linear')(x)\n",
    "\n",
    "    return Model(inputs, x, name='discriminator')\n",
    "\n",
    "discriminator = buildDisc()\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "generator_input (InputLayer) [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 14, 14, 128)       409728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 28, 28, 64)        204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 28, 28, 32)        51232     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 28, 28, 1)         801       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 1,301,505\n",
      "Trainable params: 1,300,801\n",
      "Non-trainable params: 704\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def buildGen():\n",
    "    '''Build the generator'''\n",
    "    image_resize = 7\n",
    "    # network parameters\n",
    "    kernel_size = 5\n",
    "    layer_filters = [128, 64, 32, 1]\n",
    "    \n",
    "    inputs = Input(shape=100,name='generator_input')\n",
    "    x = inputs\n",
    "\n",
    "    x = Dense(image_resize * image_resize * layer_filters[0])(x)\n",
    "    x = Reshape((image_resize, image_resize, layer_filters[0]))(x)\n",
    "\n",
    "    for filters in layer_filters:\n",
    "        if filters > layer_filters[-2]:\n",
    "            strides = 2\n",
    "        else:\n",
    "            strides = 1\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = Conv2DTranspose(filters=filters, kernel_size=kernel_size,strides=strides,padding='same')(x)\n",
    "\n",
    "    x = Activation('sigmoid')(x)\n",
    "    return Model(inputs, x, name='generator')\n",
    "\n",
    "generator = buildGen()\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = WGAN(generator=generator,discriminator=discriminator,DiscrOptimizer=RMSprop(lr=5e-5),GanOptimizer=RMSprop(lr=5e-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.generateBatchEval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gan.GenerateOutputs(xtest=gan.evaluationInpt,returnArray=False,dataViewer=vwr,save=True,View=False,epoch=0)\n",
    "gan.GenerateOutputs(batchSize=1,returnArray=False,dataViewer=vwr,save=False,View=True,epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300\n",
      "11/11 [==============================] - 52s 5s/step\n",
      "Discrimiator: (loss,acc)=(-0.013973575085401539,0.0001953125)\n",
      " \t Adversial: (loss,acc)=(-0.02002800814807415,0.0009765625)\n"
     ]
    }
   ],
   "source": [
    "gan.train(xtr,epoch=300,batch_size=1024,evalStep=(10,100), n_critic = 5,clip_value = 0.01,pathSave='D:/Project/DeepLearning/GAN/WGAN/save',dataViewer=vwr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
